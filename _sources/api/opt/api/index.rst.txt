:py:mod:`opt.api`
=================

.. py:module:: opt.api


Submodules
----------
.. toctree::
   :titlesonly:
   :maxdepth: 1

   bqm_solver/index.rst
   bqm_solver_test/index.rst
   cost_function/index.rst
   example_functions/index.rst
   functions/index.rst
   optimizer/index.rst
   optimizer_test/index.rst
   problem/index.rst
   save_conditions/index.rst


Package Contents
----------------

Classes
~~~~~~~

.. autoapisummary::

   opt.api.CallableStoringArtifacts
   opt.api.CallableWithGradient
   opt.api.CallableWithGradientStoringArtifacts
   opt.api.FunctionWithGradient
   opt.api.FunctionWithGradientStoringArtifacts
   opt.api.StoreArtifact
   opt.api.NestedOptimizer
   opt.api.Optimizer
   opt.api.SaveCondition



Functions
~~~~~~~~~

.. autoapisummary::

   opt.api.function_with_gradient
   opt.api.has_store_artifact_param
   opt.api.construct_history_info
   opt.api.optimization_result
   opt.api.always
   opt.api.every_nth



Attributes
~~~~~~~~~~

.. autoapisummary::

   opt.api.CostFunction


.. py:data:: CostFunction
   

   

.. py:class:: CallableStoringArtifacts

   Bases: :py:obj:`Protocol`\ [\ :py:obj:`S`\ , :py:obj:`T`\ ]

   A callable that stores artifacts.


.. py:class:: CallableWithGradient

   Bases: :py:obj:`Protocol`

   A callable with gradient.

   .. py:method:: gradient(params: numpy.ndarray) -> numpy.ndarray



.. py:class:: CallableWithGradientStoringArtifacts

   Bases: :py:obj:`CallableStoringArtifacts`\ [\ :py:obj:`numpy.ndarray`\ , :py:obj:`T`\ ], :py:obj:`Protocol`

   A callable with gradient that stored artifacts.

   .. py:method:: gradient(params: numpy.ndarray) -> numpy.ndarray



.. py:class:: FunctionWithGradient

   Bases: :py:obj:`NamedTuple`

   A callable with gradient.

   .. py:attribute:: function
      :annotation: :Callable[[numpy.ndarray], float]

      

   .. py:attribute:: gradient
      :annotation: :Callable[[numpy.ndarray], numpy.ndarray]

      


.. py:class:: FunctionWithGradientStoringArtifacts

   Bases: :py:obj:`NamedTuple`

   A callable with gradient that also stores artifacts.

   .. py:attribute:: function
      :annotation: :CallableStoringArtifacts

      

   .. py:attribute:: gradient
      :annotation: :Callable[[numpy.ndarray], numpy.ndarray]

      


.. py:class:: StoreArtifact

   Bases: :py:obj:`Protocol`

   A protocol describing how the artifacts are stored.


.. py:function:: function_with_gradient(function: Union[Callable[[numpy.ndarray], float], CallableStoringArtifacts], gradient: Callable[[numpy.ndarray], numpy.ndarray]) -> Union[FunctionWithGradient, FunctionWithGradientStoringArtifacts]

   Combine function and gradient into an entity adhering to protocols used by
   history recorder.

   Note that this is a preferred method for adding gradient to your function,
   as it should automatically detect whether the function stores artifact or not.


.. py:function:: has_store_artifact_param(function) -> bool

   Determine if given callable is capable of storing artifacts.

   :param function: a callable to be checked.
   :return: True, if `function` has store_artifact parameter and False otherwise.


.. py:class:: NestedOptimizer

   Bases: :py:obj:`abc.ABC`

   Optimizers that modify cost function throughout optimization.
   An example of such optimizer could be on that freezes certain
   parameters during every iteration or adds new layers of
   the underlying circuit (so called layer-by-layer optimization).

   See MockNestedOptimizer in orquestra.opt.mock_objects for an example.

   :param inner_optimizer: Optimizer object used in the inner optimization loop.
   :param recorder: recorder object which defines how to store the optimization history.

   :returns:     opt_value,
                 opt_params,
                 nit: total number of iterations of inner_optimizer,
                 nfev: total number of calls to cost function,
                 history: a list of HistoryEntrys.
                     If keep_history is False this should be an empty list.
                 gradient_history: if the cost function is a FunctionWithGradient,
                     this should be a list of HistoryEntrys representing
                     previous calls to the gradient.
   :rtype: An instance of OptimizeResult containing

   .. py:method:: inner_optimizer() -> Optimizer
      :property:

      Inner optimizer used by this optimizer.


   .. py:method:: recorder() -> opt.history.recorder.RecorderFactory
      :property:

      Factory for creating recorders of functions being minimized.


   .. py:method:: minimize(cost_function_factory: Callable[Ellipsis, opt.api.CostFunction], initial_params: numpy.ndarray, keep_history: bool = False) -> scipy.optimize.OptimizeResult

      Finds optimal parameters to minimize the cost function factory.

      :param cost_function_factory: function that generates CostFunction objects.
      :param initial_params: initial parameters used for optimization
      :param keep_history: flag indicating whether history of cost function
                           evaluations should be recorded.



.. py:class:: Optimizer(recorder: opt.history.recorder.RecorderFactory = _recorder)

   Bases: :py:obj:`abc.ABC`

   Interface for implementing different optimizers.

   :param recorder: recorder object which defines how to store the optimization history.

   .. py:method:: minimize(cost_function: opt.api.CostFunction, initial_params: numpy.ndarray, keep_history: bool = False) -> scipy.optimize.OptimizeResult

      Finds the parameters which minimize given cost function.

      :param cost_function: an object representing the cost function.
      :param initial_params: initial parameters for the cost function.
      :param keep_history: flag indicating whether history of cost function
                           evaluations should be recorded.



.. py:function:: construct_history_info(cost_function: opt.api.CostFunction, keep_history: bool) -> Dict[str, opt.history.recorder.AnyHistory]


.. py:function:: optimization_result(*, opt_value, opt_params, **kwargs) -> scipy.optimize.OptimizeResult

   Construct instance of OptimizeResult.

   The purpose of this function is to add a safety layer by detecting if required
   components of OptimizationResult are missing already during static analysis.

   :param opt_value: the final value of the function being optimized.
   :param opt_params: the parameters (arguments) for which opt_value has been achieved.
   :param kwargs: other attributes (e.g. history) that should be stored in OptimizeResult.

   :returns: An instance of OptimizeResult containing opt_value, opt_params and all of the
             other passed arguments.


.. py:class:: SaveCondition

   Bases: :py:obj:`Protocol`

   Protocol of a function determining if given call should should be saved in the
   history.


.. py:function:: always(value: Any, params: Any, call_number: int) -> bool

   Default save condition: save always.

   See parameters in SaveCondition.__call__ for explanation.


.. py:function:: every_nth(n: int) -> SaveCondition

   Save condition: every n-th step, counting from zero-th one.

   Note: this is factory function, i.e. it returns the actual save condition
   for given n.

   :param n: the integer determining which steps should be saved in history.

   :returns: Function `f` implementing the SaveCondition protocol, such that
             f(y, x, k) is True if and only if k = 0 (mod n).


